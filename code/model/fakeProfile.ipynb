{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "19lsxc89lFwYxeGwP_RoT1QVPT7X6DeO3",
      "authorship_tag": "ABX9TyP+tfyzdU2nWf2rxcD8Znm4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupammaurya6767/FakeProfileIdentifier/blob/main/fakeProfile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Title: üïµÔ∏è‚Äç‚ôÇÔ∏è Fake Profile Detector üïµÔ∏è‚Äç‚ôÄÔ∏è\n",
        "\n",
        "## Introduction:\n",
        "\n",
        "In the era of social media and online interactions, the proliferation of fake profiles has become a significant concern. üåê Fake profiles can be used for various malicious purposes, including misinformation, scams, and cyberattacks. Detecting these deceptive profiles is crucial to maintain a secure and trustworthy online environment.\n",
        "\n",
        "Our project, the Fake Profile Detector, aims to tackle this challenge using the power of machine learning and data analysis. ü§ñüíª By building an intelligent model, we endeavor to distinguish between genuine and fake profiles with a high degree of accuracy.\n",
        "\n",
        "Our mission is to create a tool that safeguards online communities and platforms by automatically identifying suspicious accounts. üë§‚ùå We believe that with the right combination of data preprocessing, feature engineering, and model selection, we can significantly improve the accuracy of fake profile detection, contributing to a safer online experience for all users."
      ],
      "metadata": {
        "id": "5Yhlrddfs-vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier"
      ],
      "metadata": {
        "id": "w-SVXtqmrYmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the training dataset\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/data/train.csv')\n",
        "# Load the testing dataset\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/data/test.csv')\n",
        "\n",
        "# Split the training dataset into features (X_train) and the target variable (y_train)\n",
        "X_train = train_data.drop('fake', axis=1)  # Features for training\n",
        "y_train = train_data['fake']  # Target variable for training\n",
        "\n",
        "# Split the testing dataset into features (X_test) and the target variable (y_test)\n",
        "X_test = test_data.drop('fake', axis=1)  # Features for testing\n",
        "y_test = test_data['fake']  # Target variable for testing\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print other classification metrics\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACvAwcTUn9uV",
        "outputId": "5294eef5-7dcb-4c53-f268-fa0a40c3d0f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.92        60\n",
            "           1       0.93      0.90      0.92        60\n",
            "\n",
            "    accuracy                           0.92       120\n",
            "   macro avg       0.92      0.92      0.92       120\n",
            "weighted avg       0.92      0.92      0.92       120\n",
            "\n",
            "[[56  4]\n",
            " [ 6 54]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation:\n",
        "\n",
        "Augment dataset by generating synthetic examples of both fake and genuine profiles. Techniques like oversampling, SMOTE (Synthetic Minority Over-sampling Technique), or data augmentation for text data can be applied to balance your dataset and potentially improve model performance."
      ],
      "metadata": {
        "id": "XDa6rJ6yrlcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Now, you can train your model on X_train_resampled and y_train_resampled\n"
      ],
      "metadata": {
        "id": "RwrAJsigpSIY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection:\n",
        "\n",
        "Experiment with different machine learning algorithms beyond Random Forest, such as Gradient Boosting (e.g., XGBoost, LightGBM), Support Vector Machines (SVM), or neural networks. Each algorithm may capture different patterns in the data."
      ],
      "metadata": {
        "id": "PLoQAOZXrvPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the XGBoost model\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLdJCF0_ovFp",
        "outputId": "59771e81-cc11-4c8d-cfb0-1195d9ad1233"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.95\n"
          ]
        }
      ]
    }
  ]
}